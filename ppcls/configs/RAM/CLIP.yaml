# global configs
Global:
  checkpoints: null
  pretrained_model: "ViT-B-32.pdparams" # pretrain model for ram and ram plus, default random initilize
  output_dir: ./output/
  device: cpu
  save_interval: 1
  eval_during_train: True
  eval_interval: 1
  epochs: 120
  print_batch_step: 1
  use_visualdl: False
  # used for static mode and model export
  image_shape: [3, 224, 224]
  save_inference_dir: ./inference_text



# model architecture
Arch:
  name: CLIP_vit_base_patch32_224_with_TextEncoder
  clip: "text"

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: RAMPretrainDataset
      ann_file: [./visual-genome/vg_ram.json]
      tag_list: 'ppcls/utils/ram/ram_tag_list.txt'
      model_name: "RAM"
      transform_ops_ram:
        - ResizeImage:
            size: 384
            interpolation: bicubic
            backend: pil
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
        - ToCHWImage:
      transform_ops_clip:        
        - ResizeImage:
            size: 224
            interpolation: bicubic
            backend: pil
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.48145466, 0.4578275, 0.40821073]
            std: [0.26862954, 0.26130258, 0.27577711]
            order: ''
        - ToCHWImage:

    sampler:
      name: DistributedBatchSampler
      batch_size: 52
      drop_last: False
      shuffle: True
    loader:
      num_workers: 4
      use_shared_memory: True

  Eval:
    dataset: 
      name: RAMPretrainDataset
      ann_file: [./visual-genome/vg_ram.json]
      tag_list: 'ppcls/utils/ram/ram_tag_list.txt'
      model_name: "RAM" 
      transform_ops_ram:
        - ResizeImage:
            size: 384
            interpolation: bicubic
            backend: pil
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
        - ToCHWImage:
      transform_ops_clip:        
        - ResizeImage:
            size: 224
            interpolation: bicubic
            backend: pil
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.48145466, 0.4578275, 0.40821073]
            std: [0.26862954, 0.26130258, 0.27577711]
            order: ''
        - ToCHWImage:

    sampler:
      name: DistributedBatchSampler
      batch_size: 52
      drop_last: False
      shuffle: True
    loader:
      num_workers: 4
      use_shared_memory: True
 
Infer:
  infer_imgs: docs/images/inference_deployment/whl_demo.jpg
  batch_size: 1
  transforms:
    - DecodeImage:
        to_rgb: True
        channel_first: False
    - ResizeImage:
        resize_short: 224
    - CropImage:
        size: 224
    - NormalizeImage:
          scale: 1.0/255.0
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          order: ''
    - ToCHWImage:
  PostProcess:
    name: RamOutPut
    language: "cn"
    tag_list: "ppcls/utils/ram/ram_tag_list.txt"
    tag_list_chinese: "ppcls/utils/ram/ram_tag_list_chinese.txt"
    ram_class_threshold_path: "ppcls/utils/ram/ram_tag_list_threshold.txt"
