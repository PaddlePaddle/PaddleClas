# global configs
Global:
  checkpoints: null
  pretrained_model: null
  output_dir: ./output/
  device: gpu
  save_interval: 1
  eval_during_train: True
  eval_interval: 1
  epochs: 350
  print_batch_step: 20
  use_visualdl: False
  train_mode: progressive  # progressive training
  # used for static mode and model export
  image_shape: [3, 384, 384]
  save_inference_dir: ./inference

AMP:
  scale_loss: 65536
  use_dynamic_loss_scaling: True
  # O1: mixed fp16
  level: O1

EMA:
  decay: 0.9999

# model architecture
Arch:
  name: EfficientNetV2_S
  class_num: 1000
  use_sync_bn: True

# loss function config for traing/eval process
Loss:
  Train:
    - CELoss:
        weight: 1.0
        epsilon: 0.1
  Eval:
    - CELoss:
        weight: 1.0

Optimizer:
  name: Momentum
  momentum: 0.9
  lr:
    name: Cosine
    learning_rate: 0.65 # 8gpux128bs
    warmup_epoch: 5
  regularizer:
    name: L2
    coeff: 0.00001

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: ImageNetDataset
      image_root: ./dataset/ILSVRC2012/
      cls_label_path: ./dataset/ILSVRC2012/train_list.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 171
            progress_size: [171, 214, 257, 300]
            scale: [0.05, 1.0]
        - RandFlipImage:
            flip_code: 1
        - RandAugmentV2:
            num_layers: 2
            magnitude: 5.0
            progress_magnitude: [5.0, 8.3333333333, 11.66666666667, 15.0]
        - NormalizeImage:
            scale: 1.0
            mean: [128.0, 128.0, 128.0]
            std: [128.0, 128.0, 128.0]
            order: ""
      batch_transform_ops:
        - MixupOperator:
            alpha: 0.2

    sampler:
      name: DistributedBatchSampler
      batch_size: 128
      drop_last: True
      shuffle: True
    loader:
      num_workers: 8
      use_shared_memory: True

  Eval:
    dataset:
      name: ImageNetDataset
      image_root: ./dataset/ILSVRC2012/
      cls_label_path: ./dataset/ILSVRC2012/val_list.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - CropImageAtRatio:
            size: 384
            pad: 32
            interpolation: bilinear
        - NormalizeImage:
            scale: 1.0
            mean: [128.0, 128.0, 128.0]
            std: [128.0, 128.0, 128.0]
            order: ""
    sampler:
      name: DistributedBatchSampler
      batch_size: 128
      drop_last: False
      shuffle: False
    loader:
      num_workers: 8
      use_shared_memory: True

Infer:
  infer_imgs: docs/images/inference_deployment/whl_demo.jpg
  batch_size: 10
  transforms:
    - DecodeImage:
        to_rgb: True
        channel_first: False
    - CropImageAtRatio:
        size: 384
        pad: 32
        interpolation: bilinear
    - NormalizeImage:
        scale: 1.0
        mean: [128.0, 128.0, 128.0]
        std: [128.0, 128.0, 128.0]
        order: ""
  PostProcess:
    name: Topk
    topk: 5
    class_id_map_file: ppcls/utils/imagenet1k_label_list.txt

Metric:
  Train:
    - TopkAcc:
        topk: [1, 5]
  Eval:
    - TopkAcc:
        topk: [1, 5]
