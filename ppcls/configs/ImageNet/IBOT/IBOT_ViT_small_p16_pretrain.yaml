# global configs
Global:
  checkpoints: null
  pretrained_model: null
  train_mode: ibot

  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
  use_fp16: True
  weight_decay: 0.04
  weight_decay_end: 0.4
  epochs: 800
  freeze_last_layer: 1
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1e-06

#  num_workers: 10

  global_crops_scale: [ 0.25, 1.0 ]
  local_crops_number: 10
  local_crops_scale: [ 0.05, 0.25 ]
  pred_ratio: [0, 0.3]
  pred_ratio_var: [0 0.2]

  seed: 0
  ngpus: 8
  nodes: 2
  device: gpu
  optimizer: adamw
  momentum_teacher: 0.996
  output_dir: ./output_ibot_vit_small_p16/

  eval_during_train: False
  eval_interval: 1
  print_batch_step: 20
  use_visualdl: True
  save_interval: 1

AMP:
  scale_loss: 128.0
  use_dynamic_loss_scaling: True
  # O1: mixed fp16
  level: O1

# model architecture
Arch:
  name: IBOT
  mode: pretrain
  arch: vit_small
  patch_size: 16
  out_dim: 8192
  norm_last_layer: False
  shared_head: True
  class_num: 1000

# loss function config for traing/eval process
Loss:
  Train:
    - IBOTLoss:
        weight: 1.0
        out_dim: 8192
        ncrops: 12   # 10 + 2
        warmup_teacher_temp: 0.04
        teacher_temp: 0.07
        warmup_teacher_temp_epochs: 30
        nepochs: 800
  Eval:
    - CELoss:
        weight: 1.0


Optimizer:
  name: AdamW
  weight_decay: 0.04
  no_weight_decay_name: norm bias
  clip_norm: 0
  lr:
    # for 8 cards
    name: Constant
    learning_rate: 5e-4


# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: IBOTDataset
      image_root: ../dataset/ILSVRC2012/
      cls_label_path: ../dataset/ILSVRC2012/train_list.txt
      transform_ops:
        - IBOTAugmentation:
            transform_ops_global:
              - DecodeImage:
                  to_np: False
                  to_rgb: True
                  channel_first: False
                  backend: pil
              - DataAugmentationIBOT:
                  global_crops_scale: [ 0.25, 1.0 ]
                  local_crops_scale: [ 0.05, 0.25 ]
                  local_crops_number: 10
    sampler:
      name: DistributedBatchSampler
      batch_size: 32
      drop_last: True
      shuffle: True
    loader:
      num_workers: 10
      use_shared_memory: True

  Eval:
    dataset: 
      name: IBOTDataset
      image_root: ../dataset/ILSVRC2012/
      cls_label_path: ../dataset/ILSVRC2012/val_list.txt
      transform_ops:
        - IBOTAugmentation:
            transform_ops_global:
              - DecodeImage:
                  to_np: False
                  to_rgb: True
                  channel_first: False
                  backend: pil
              - DataAugmentationIBOT:
                  global_crops_scale: [ 0.25, 1.0 ]
                  local_crops_scale: [ 0.05, 0.25 ]
                  local_crops_number: 10
    sampler:
      name: DistributedBatchSampler
      batch_size: 32
      drop_last: True
      shuffle: False
    loader:
      num_workers: 8
      use_shared_memory: True

#Infer:
#  infer_imgs: docs/images/inference_deployment/whl_demo.jpg
#  batch_size: 10
#  transforms:
#    - DecodeImage:
#        to_rgb: True
#        channel_first: False
#    - ResizeImage:
#        resize_short: 256
#    - CropImage:
#        size: 224
#    - NormalizeImage:
#        scale: 1.0/255.0
#        mean: [0.485, 0.456, 0.406]
#        std: [0.229, 0.224, 0.225]
#        order: ''
#    - ToCHWImage:
#  PostProcess:
#    name: Topk
#    topk: 5
#    class_id_map_file: ppcls/utils/imagenet1k_label_list.txt
#
#Metric:
#    Train:
#    - DistillationTopkAcc:
#        model_key: "Student"
#        topk: [1, 5]
#    Eval:
#    - DistillationTopkAcc:
#        model_key: "Student"
#        topk: [1, 5]