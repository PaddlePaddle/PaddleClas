# global configs
Global:
  checkpoints: null
  pretrained_model: null
  output_dir: "./output/"
  device: "gpu"
  save_interval: 1
  eval_during_train: True
  eval_interval: 1
  epochs: 20
  print_batch_step: 10
  use_visualdl: False
  # used for static mode and model export
  image_shape: [3, 224, 224]
  save_inference_dir: "./inference"
  use_multilabel: True

# model architecture
Arch:
  name: "SwinTransformer_tiny_patch4_window7_224"
  pretrained: True
  class_num: 26

# loss function config for traing/eval process
Loss:
  Train:
    - MultiLabelLoss:
        weight: 1.0
        weight_ratio: True
        size_sum: True
  Eval:
    - MultiLabelLoss:
        weight: 1.0
        weight_ratio: True
        size_sum: True

Optimizer:
  name: Momentum
  momentum: 0.9
  lr:
    name: Cosine
    learning_rate: 0.01
    warmup_epoch: 5
  regularizer:
    name: 'L2'
    coeff: 0.0005
  #clip_norm: 10

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: MultiLabelDataset
      image_root: "dataset/pa100k/"
      cls_label_path: "dataset/pa100k/train_list.txt"
      label_ratio: True
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - ResizeImage:
            size: [224, 224]
        - Padv2:
            size: [244, 244]
            pad_mode: 1
            fill_value: 0
        - RandomCropImage:
            size: [224, 224]
        - RandFlipImage:
            flip_code: 1
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
    sampler:
      name: DistributedBatchSampler
      batch_size: 64
      drop_last: True
      shuffle: True
    loader:
      num_workers: 4
      use_shared_memory: True
  Eval:
    dataset:
      name: MultiLabelDataset
      image_root: "dataset/pa100k/"
      cls_label_path: "dataset/pa100k/val_list.txt"
      label_ratio: True
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - ResizeImage:
            size: [224, 224]
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
    sampler:
      name: DistributedBatchSampler
      batch_size: 64
      drop_last: False
      shuffle: False
    loader:
      num_workers: 4
      use_shared_memory: True

Infer:
  infer_imgs: deploy/images/PULC/person_attribute/090004.jpg
  batch_size: 10
  transforms:
    - DecodeImage:
        to_rgb: True
        channel_first: False
    - ResizeImage:
        size: [224, 224]
    - NormalizeImage:
        scale: 1.0/255.0
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
        order: ''
    - ToCHWImage:
  PostProcess:
    name: PersonAttribute
    threshold: 0.5  #default threshold
    glasses_threshold: 0.3  #threshold only for glasses
    hold_threshold: 0.6 #threshold only for hold

Metric:
  Eval:
    - ATTRMetric:


