# global configs
Global:
  checkpoints: null
  pretrained_model: null
  output_dir: ./output/face_arcface_mobilefacenet-128
  device: gpu
  save_interval: 1
  eval_during_train: True
  eval_interval: 1
  epochs: 25
  print_batch_step: 20
  use_visualdl: False
  eval_mode: face_recognition
  retrieval_feature_from: backbone 
  flip_test: True
  feature_normalize: False
  re_ranking: False
  use_dali: False
  # used for static mode and model export
  image_shape: [3, 112, 112]
  save_inference_dir: ./inference

AMP:
  scale_loss: 27648
  use_dynamic_loss_scaling: True
  # O1: mixed fp16
  level: O1

# model architecture
Arch:
  name: RecModel
  infer_output_key: features
  infer_add_softmax: False

  Backbone:
    name: MobileFaceNet_128
  Head:
    name: ArcMargin
    embedding_size: 128
    class_num: 93431
    margin: 0.5
    scale: 64
# loss function config for traing/eval process
Loss:
  Train:
    - CELoss:
        weight: 1.0

# Optimizer:
#   name: Momentum
#   momentum: 0.9
#   lr:
#     name: Piecewise
#     decay_epochs: [10, 16, 22]
#     values: [0.02, 0.002, 0.0002, 0.00002]
#   regularizer:
#     name: L2
#     coeff: 0.00001
#   clip_norm: 10
Optimizer:
  name: AdamW
  beta1: 0.9
  beta2: 0.999
  epsilon: 1e-8
  weight_decay: 0.05
  one_dim_param_no_weight_decay: True
  lr:
    # for 8 cards
    name: Cosine
    learning_rate: 4e-3  # lr 4e-3 for total_batch_size 4096
    eta_min: 1e-6
    warmup_epoch: 1
    warmup_start_lr: 0

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: ImageNetDataset
      image_root: /mnt/wxq/datasets/MS1M_v3/
      #image_root: ./dataset/MS1M_v2/
      cls_label_path: /mnt/wxq/datasets/MS1M_v3/label.txt
      #cls_label_path: dataset/MS1M_v2/train_list_10w.txt
      delimiter: "\t"
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
            backend: cv2
        - RandFlipImage:
            flip_code: 1
        - ResizeImage:
            size: [112, 112]
            return_numpy: False
            interpolation: bilinear
            backend: cv2
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5, 0.5, 0.5]
            std: [0.5, 0.5, 0.5]
            order: hwc
    sampler:
      name: DistributedBatchSampler
      batch_size: 128
      drop_last: False
      shuffle: True
      #sample_method: "id_avg_prob"
      #id_list: [50030, 80700, 92019, 96015] # be careful when set relabel=True
      #ratio: [4, 4]
    loader:
      num_workers: 8
      use_shared_memory: True

  Eval:
    dataset:
      name: FiveFaceEvalDataset
      val_data_path: /mnt/wxq/datasets/MS1M_v3/
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
            backend: cv2
        - ResizeImage:
            size: [112, 112]
            return_numpy: False
            interpolation: bilinear
            backend: cv2
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5, 0.5, 0.5]
            std: [0.5, 0.5, 0.5]
            order: hwc
    sampler:
      name: DistributedBatchSampler
      batch_size: 64
      drop_last: False
      shuffle: False
    loader:
      num_workers: 4
      use_shared_memory: True

Metric:
  Eval:
    - BestAccOnFiveDatasets: {}
