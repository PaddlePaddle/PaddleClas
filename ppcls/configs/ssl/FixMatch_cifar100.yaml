# global configs
Global:
  checkpoints: null
  pretrained_model: './torch2paddle'
  output_dir: ./output
  device: gpu
  save_interval: 100
  eval_during_train: True
  eval_interval: 1
  epochs: 1024
  iter_per_epochs: 1024
  print_batch_step: 20
  use_visualdl: False
  use_dali: False
  train_mode: fixmatch
  # used for static mode and model export
  image_shape: [3, 224, 224]
  save_inference_dir: ./inference

SSL:
  tempture: 1
  threshold: 0.95

EMA:
  decay: 0.999

# AMP:
#   scale_loss: 65536
#   use_dynamic_loss_scaling: True
#   # O1: mixed fp16
#   level: O1

# model architecture
Arch:
  name: WideResNet
  depth: 28
  widen_factor: 8
  dropout: 0
  num_classes: 100

# loss function config for traing/eval process
Loss:
  Train:
    - CELoss:
        weight: 1.0
        reduction: "mean"
  Eval:
    - CELoss:
        weight: 1.0
UnLabelLoss:
  Train:
    - CELoss:
        weight: 1.0
        reduction: "none"

Optimizer:
  name: Momentum
  momentum: 0.9
  use_nesterov: True
  no_weight_decay_name: bn bias
  lr:
    name: Cosine
    learning_rate: 0.03
    warmup_epoch: 0
  regularizer:
    name: L2
    coeff: 0.001

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: Cifar100
      data_file: None
      mode: 'train'
      download: True
      backend: 'pil'
      sample_per_label: 4
      transform_ops:
        - RandFlipImage:
            flip_code: 1
        - Pad_paddle_vision:
            padding: 4
            padding_mode: reflect
        - RandCropImageV2:
            size: [32, 32]
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5071, 0.4867, 0.4408]
            std: [0.2675, 0.2565, 0.2761]
            order: hwc
    sampler:
      name: DistributedBatchSampler
      batch_size: 16
      drop_last: False
      shuffle: True
    loader:
      num_workers: 4
      use_shared_memory: True

  UnLabelTrain:
    dataset:
      name: Cifar100
      data_file: None
      mode: 'train'
      download: True
      backend: 'pil'
      sample_per_label: None
      transform_ops_weak:
        - RandFlipImage:
            flip_code: 1
        - Pad_paddle_vision:
            padding: 4
            padding_mode: reflect
        - RandCropImageV2:
            size: [32, 32]
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5071, 0.4867, 0.4408]
            std: [0.2675, 0.2565, 0.2761]
            order: hwc
      transform_ops_strong:
        - RandFlipImage:
            flip_code: 1
        - Pad_paddle_vision:
            padding: 4
            padding_mode: reflect
        - RandCropImageV2:
            size: [32, 32]
        - RandAugment:
            num_layers: 2
            magnitude: 10
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5071, 0.4867, 0.4408]
            std: [0.2675, 0.2565, 0.2761]
            order: hwc
    sampler:
      name: DistributedBatchSampler
      batch_size: 112
      drop_last: False
      shuffle: True
    loader:
      num_workers: 4
      use_shared_memory: True


  Eval:
    dataset:
      name: Cifar100
      data_file: None
      mode: 'test'
      download: True
      backend: 'pil'
      sample_per_label: None
      transform_ops:
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.5071, 0.4867, 0.4408]
            std: [0.2675, 0.2565, 0.2761]
            order: hwc
    sampler:
      name: DistributedBatchSampler
      batch_size: 16
      drop_last: False
      shuffle: True
    loader:
      num_workers: 4
      use_shared_memory: True


Metric:
  Eval:
    - TopkAcc:
        topk: [1, 5]