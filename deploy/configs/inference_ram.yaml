Global:
  infer_imgs: "docs/images/inference_deployment/whl_demo.jpg"
  inference_model_dir: "./inference"
  batch_size: 1
  use_gpu: False
  enable_mkldnn: False
  cpu_num_threads: 10
  enable_benchmark: True
  use_fp16: False
  ir_optim: False # do not set it as True since there is a bug which leads the invaild initilize for predictor
  use_tensorrt: False
  gpu_mem: 8000
  enable_profile: False

PreProcess:
  transform_ops:
    - ResizeImage:
        resize_short: 384
    - CropImage:
        size: 384
    - NormalizeImage:
        scale: 1.0/255.0
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
        order: ""
        channel_num: 3
    - ToCHWImage:
PostProcess:
  main_indicator: RamOutPut
  RamOutPut:
    language: "en"
    tag_list: "ppcls/utils/ram/ram_tag_list.txt"
    tag_list_chinese: "ppcls/utils/ram/ram_tag_list_chinese.txt"
    ram_class_threshold_path: "ppcls/utils/ram/ram_tag_list_threshold.txt"


