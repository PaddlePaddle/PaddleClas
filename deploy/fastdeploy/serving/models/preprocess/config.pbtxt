name: "preprocess"
backend: "python"
max_batch_size: 16

input [
  {
    name: "preprocess_input"
    data_type: TYPE_UINT8
    dims: [ -1, -1, 3 ]
  }
]

output [
  {
    name: "preprocess_output"
    data_type: TYPE_FP32
    dims: [ 3, 224, 224 ]
  }
]

instance_group [
  {
    # The number of instances is 1
    count: 1
    # Use CPU, GPU inference option is:KIND_GPU
    kind: KIND_CPU
    # The instance is deployed on the 0th GPU card
    # gpus: [0]
  }
]